{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"article-based chatbot.ipynb","provenance":[{"file_id":"/v2/external/notebooks/snippets/importing_libraries.ipynb","timestamp":1621362738663}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"0MTjf0P62e4_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628969066940,"user_tz":-60,"elapsed":3305,"user":{"displayName":"Ruei-Huan Rao","photoUrl":"","userId":"13183932021173535053"}},"outputId":"ef75627d-fc9f-4a19-f111-99c75a9882ab"},"source":["pip install newspaper3k"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: newspaper3k in /usr/local/lib/python3.7/dist-packages (0.2.8)\n","Requirement already satisfied: feedparser>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (6.0.8)\n","Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (4.6.3)\n","Requirement already satisfied: tldextract>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (3.1.0)\n","Requirement already satisfied: cssselect>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (1.1.0)\n","Requirement already satisfied: feedfinder2>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (0.0.4)\n","Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (2.23.0)\n","Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (4.2.6)\n","Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (3.13)\n","Requirement already satisfied: jieba3k>=0.35.1 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (0.35.1)\n","Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (2.8.2)\n","Requirement already satisfied: tinysegmenter==0.3 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (0.3)\n","Requirement already satisfied: nltk>=3.2.1 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (3.2.5)\n","Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from feedfinder2>=0.0.4->newspaper3k) (1.15.0)\n","Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.7/dist-packages (from feedparser>=5.2.1->newspaper3k) (1.0.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k) (1.24.3)\n","Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from tldextract>=2.0.1->newspaper3k) (3.0.12)\n","Requirement already satisfied: requests-file>=1.4 in /usr/local/lib/python3.7/dist-packages (from tldextract>=2.0.1->newspaper3k) (1.5.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"B8N1qh1pxAyk"},"source":["# import the libraries\n","import numpy as np\n","import random\n","\n","import torch\n","import nltk\n","nltk.download('punkt', quiet=True)\n","import tensorflow as tf\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","from newspaper import Article\n","\n","import warnings\n","warnings.filterwarnings('ignore')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nYGH9XE43iwF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628978417027,"user_tz":-60,"elapsed":3898,"user":{"displayName":"Ruei-Huan Rao","photoUrl":"","userId":"13183932021173535053"}},"outputId":"a167f728-af9f-4bef-ee4e-d45c91b1b5a4"},"source":["# download the article\n","article_input = input(\"Choose your fancy article link or press \\\"enter\\\" for the default article (about machine learning)\\n\")\n","default = ['', 'okay', 'default', 'ok', 'fine', '']\n","if article_input.lower() in default:\n","  url = 'https://en.wikipedia.org/wiki/Machine_learning'\n","else:\n","  url = str(article_input)\n","article = Article(url)\n","article.download()\n","article.parse()\n","article.nlp()\n","print(f'The topic we are talking about: \"{article.title}\"')\n","corpus = article.text"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Choose your fancy article link or \"enter\" the default article (about machine learning)\n","\n","The topic we are talking about: \"Machine learning\"\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tnZoSaKX8jOO"},"source":["# create a list of sentences\n","sentence_list = nltk.sent_tokenize(corpus) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oy3Qi_7bI0fT"},"source":["# a function to return a random greeting response to a user's greeting\n","def greeting_response(text):\n","  text = text.lower()\n","\n","  # bot's greeting reponse\n","  bot_greetings = [\"Hey :-)\", \"Hello, thanks for visiting\", \"Hi there, what can I do for you?\",\n","                   \"Hi there, how can I help?\", \"Hello, thanks for asking\", \"Good to see you again\"]\n","  # user's greeting\n","  user_greetings = ['hi', 'hey', 'hello']\n","\n","  for word in text.split():\n","    if word in user_greetings:\n","      return random.choice(bot_greetings)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y9bCAT2cK4AA"},"source":["def index_sort(list_var):\n","  index = list(range(0, len(list_var))\n","  \n","  for i in range(len(list_var)):\n","    for j in range(len(list_var)):\n","      if list_var[index[i]] > list_var[index[j]]:\n","        # swap\n","        temp = index[i]\n","        index[i] = index[j]\n","        index[j] = temp\n","\n","  return index"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zLrXBagGJs3P"},"source":["def bot_response(user_input):\n","  # lower the input and include it into the article\n","  user_input = user_input.lower()\n","  sentence_list.append(user_input)\n","\n","  # build bag of words of each of the sentences\n","  vectoriser = CountVectorizer()\n","  bag_of_words = vectoriser.fit_transform(sentence_list)\n","  \n","  # calculate the similarity (distance)\n","  similarity_scores = cosine_similarity(bag_of_words[-1], bag_of_words)\n","  similarity_scores_list = similarity_scores.flatten()\n","  \n","  # sort in accordance with the similarity score\n","  # remove the first sentence since it is the input itself\n","  index = index_sort(similarity_scores_list)\n","  index = index[1:]\n","  \n","  response = False\n","  \n","  # return all context which is similar with the input\n","  bot_res = ''\n","  for j, i in enumerate(range(len(index))):\n","    if similarity_scores_list[index[i]] > 0.0:\n","      bot_res = bot_res + ' ' + sentence_list[index[i]]\n","      response = True\n","      j += 1\n","    if j > 2:\n","      break\n","  \n","  if response == False:\n","    bot_res = bot_res + ' ' + \"My apologies, I don't get it...\"\n","\n","  # remove the input sentence\n","  sentence_list.remove(user_input)\n","\n","  return bot_res"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PDwyfJX8MV6U","executionInfo":{"status":"ok","timestamp":1628976154225,"user_tz":-60,"elapsed":25701,"user":{"displayName":"Ruei-Huan Rao","photoUrl":"","userId":"13183932021173535053"}},"outputId":"c284a019-d34d-49e1-b748-571a7ea44c1c"},"source":["# execute the bot\n","exit_list = ['exit', 'see you later', 'bye', 'quit', 'breat', 'q']\n","print(\"bot: Hello! How can I help you?\")\n","while True:\n","  user_input = input()\n","  if user_input.lower() in exit_list:\n","    print('Bot: Chat with you later !')\n","    break\n","\n","  else:\n","    if greeting_response(user_input) != None:\n","      print('Bot: ' + greeting_response(user_input))\n","    else:\n","      print('Bot: ' + bot_response(user_input))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["bot: Hello! How can I help you?\n","machine learning\n","Bot:  machine learning Learning classifier systems (LCS) are a family of rule-based machine learning algorithms that combine a discovery component, typically a genetic algorithm, with a learning component, performing either supervised learning, reinforcement learning, or unsupervised learning. [3]\n","\n","A subset of machine learning is closely related to computational statistics, which focuses on making predictions using computers; but not all machine learning is statistical learning.\n","algorithom\n","Bot:  algorithom\n","q\n","Bot: Chat with you later !\n"],"name":"stdout"}]}]}