{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"intents-based chatbot.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"mount_file_id":"14ybrq9SsZ5Oef-axVQfGIYhUd6p4kI1H","authorship_tag":"ABX9TyNQyiDGkHO92zdCQO859ouB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"y1WKZ2oo7ebs"},"source":["# Import libraries"]},{"cell_type":"code","metadata":{"id":"Peuf2hHvTffa"},"source":["import numpy as np\n","import random\n","import json\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","\n","import nltk\n","nltk.download('punkt')\n","from nltk.stem.porter import PorterStemmer\n","stemmer = PorterStemmer()\n","\n","# check if GPU is available\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N4StMv7o6QdD"},"source":["# Build the functions"]},{"cell_type":"code","metadata":{"id":"mJNfFnzw6ZXt"},"source":["def tokenise(sentence):\n","    \"\"\"\n","    split sentence into an array of tokens\n","    \"\"\"\n","    return nltk.word_tokenize(sentence)\n","\n","def lower_stem(word):\n","    \"\"\"\n","    stemming = find the root form of the word\n","    words = [\"organize\", \"organizes\", \"organizing\"]\n","          -> [\"organ\", \"organ\", \"organ\"]\n","    \"\"\"\n","    return stemmer.stem(word.lower())\n","\n","def bag_of_words(tokenised_sentence, words):\n","    \"\"\"\n","    return bag of words array: 1 indicates each known word that exists in the sentence, 0 otherwise\n","    tokened_sentence = ['may', 'I', 'have', 'a', 'look']\n","    words = [\"hi\", \"have\", \"how\", \"may\", \"you\", \"bye\", \"a\", \"wonder\"]\n","    bag   = [ 0,      1,     0,     1,     0,     0,    1,      0   ]   \n","    \"\"\"\n","    # stem each word\n","    sentence_words = [lower_stem(word) for word in tokenised_sentence]\n","    # initialize bag with 0 for each word\n","    bag = np.zeros(len(words), dtype=np.float32)\n","    for idx, w in enumerate(words):\n","        if w in sentence_words: \n","            bag[idx] = 1\n","    return bag"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2wEkcoTu6f9D"},"source":["# Build the model"]},{"cell_type":"code","metadata":{"id":"QSHgtqEm6b_S"},"source":["'''\n","build neural network:\n","  - three linear layers\n","  - activation layer: ReLU\n","  - dropout ratio: 0.15\n","'''\n","class NN(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size):\n","        super().__init__()\n","        self.linear_layer_1 = nn.Linear(input_size, hidden_size) \n","        self.linear_layer_2 = nn.Linear(hidden_size, hidden_size) \n","        self.linear_layer_3 = nn.Linear(hidden_size, output_size)\n","        self.relu = nn.ReLU()\n","        self.dropout = nn.Dropout(0.15)\n","    \n","    def forward(self, x):\n","        out = self.linear_layer_1(x)\n","        out = self.dropout(out)\n","        out = self.relu(out)\n","        out = self.linear_layer_2(out)\n","        out = self.dropout(out)\n","        out = self.relu(out)\n","        out = self.linear_layer_3(out)\n","        return out"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_JCsjWpd7wQZ"},"source":["# Load and build the dataset"]},{"cell_type":"code","metadata":{"id":"flaXqv7RL54v"},"source":["intents_path = \"/content/drive/MyDrive/UCD_Programmes/Summer/ACM40960_Projects_in_Maths_Modelling/My_Project/dataset/intents.json\"\n","with open(intents_path, 'r') as f:\n","    intents = json.load(f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8K_rpPfROJlx"},"source":["all_words = []\n","tags = []\n","xy = []\n","# loop through each sentence in our intents patterns\n","for intent in intents['intents']:\n","  tag = intent['tag']\n","  # add to tag list\n","  tags.append(tag)\n","  for pattern in intent['patterns']:\n","    # tokenize each word in the sentence\n","    w = tokenise(pattern)\n","    # add to our words list\n","    all_words.extend(w)\n","    # add to xy pair\n","    xy.append((w, tag))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NA5bc_zrQD0h"},"source":["# lower, stem and eliminate punctuation words \n","all_words = [lower_stem(w) for w in all_words if w.isalnum()]\n","\n","# remove duplicates and sort\n","all_words = sorted(set(all_words))\n","tags = sorted(set(tags))\n","\n","print(len(xy), \"patterns\")\n","print(len(tags), \"tags:\", tags)\n","print(len(all_words), \"unique stemmed words:\", all_words)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0QJsq9J2VwoM"},"source":["# create training data\n","x_train = []\n","y_train = []\n","for (tokenised_sentence, tag) in xy:\n","  # x: bag of words for each pattern_sentence\n","  bag = bag_of_words(tokenised_sentence, all_words)\n","  x_train.append(bag)\n","  # y: PyTorch CrossEntropyLoss needs only class labels, not one-hot\n","  label = tags.index(tag)\n","  y_train.append(label)\n","\n","x_train = np.array(x_train)\n","y_train = np.array(y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G-iNXo1BY0gC"},"source":["print(x_train.shape)\n","print(y_train.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SycrEiaHORqI"},"source":["class ChatDataset(Dataset):\n","  def __init__(self):\n","    self.n_samples = len(x_train)\n","    self.x_data = x_train\n","    self.y_data = y_train\n","\n","  # support indexing such that dataset[i] can be used to get i-th sample\n","  def __getitem__(self, index):\n","    return self.x_data[index], self.y_data[index]\n","\n","  # we can call len(dataset) to return the size\n","  def __len__(self):\n","    return self.n_samples"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3chep7Wn9ku6"},"source":["# Model training"]},{"cell_type":"code","metadata":{"id":"jG2cZ-BPTV5T"},"source":["# set hyper-parameters \n","epoches = 200\n","batch_size = 5\n","learning_rate = 0.001\n","input_size = x_train.shape[1]\n","hidden_size = 64\n","output_size = len(tags)\n","print(input_size, output_size)\n","\n","# build the training dataset\n","dataset = ChatDataset()\n","train_loader = DataLoader(dataset=dataset,\n","                          batch_size=batch_size,\n","                          shuffle=True,\n","                          num_workers=0)\n","\n","# initialise the model\n","model = NN(input_size, hidden_size, output_size).to(device)\n","\n","# define loss function\n","criterion = nn.CrossEntropyLoss()\n","\n","# define optimisation function\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# start training the model\n","for epoch in range(epoches):\n","  for (words, labels) in train_loader:\n","\n","    # initialise the gradient cache\n","    optimizer.zero_grad()\n","\n","    # run in the device (either GPU or CPU)\n","    words = words.to(device)\n","    labels = labels.to(dtype=torch.long).to(device)\n","    \n","    # Forward pass\n","    outputs = model(words)\n","\n","    # calculate the loss\n","    loss = criterion(outputs, labels)\n","    \n","    # backward-prapagation\n","    loss.backward()\n","\n","    # update the parameters\n","    optimizer.step()\n","      \n","  if (epoch+1) % 20 == 0:\n","    print (f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.3f}')\n","\n","print(f'final loss: {loss.item():.3f}')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vzLaBzFk77QQ"},"source":["model.eval()\n","with torch.no_grad():\n","  print(\"Let's chat! (type 'quit' to exit)\")\n","\n","  exit_list = ['exit', 'see you later', 'bye', 'quit', 'breat', 'q']\n","  while True:\n","    sentence = input(\"You: \")\n","    if sentence.lower() in exit_list:\n","      print(\"Bot: See you!\")\n","      break\n","\n","    sentence = tokenise(sentence)\n","    X = bag_of_words(sentence, all_words)\n","    X = X.reshape(1, X.shape[0])\n","    X = torch.from_numpy(X).to(device)\n","\n","    output = model(X)\n","    _, predicted = torch.max(output, dim=1)\n","\n","    tag = tags[predicted.item()]\n","\n","    probs = torch.softmax(output, dim=1)\n","    prob = probs[0][predicted.item()]\n","    if prob.item() > 0.6:\n","        for intent in intents['intents']:\n","            if tag == intent[\"tag\"]:\n","                print(f\"Bot: {random.choice(intent['responses'])}\")\n","    else:\n","        print(f\"Bot: My apologies, I don't get it...\")"],"execution_count":null,"outputs":[]}]}